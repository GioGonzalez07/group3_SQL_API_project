{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the data for the rest of 2016 of **main** cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the url\n",
    "url = \"https://meteostat.p.rapidapi.com/stations/daily\"\n",
    "\n",
    "# Settings:\n",
    "stations = [\n",
    "            '74486',            # New York - John F. Kennedy Airport\n",
    "            '72509',            # Boston Logan International Airport\n",
    "            '72405'#,            # Washington D.C. National Airport\n",
    "#            '72502',            # New Jersey - Newark Airport\n",
    "#            '72202',            #'Miami International Airport'\n",
    "#            '72243',            #'Houston, TX Intercontinental'\n",
    "#            '72494',            #'San Francisco Airport'\n",
    "#            '72793'             # Seattle-Tacoma Airport\n",
    "            ]\n",
    "\n",
    "start_dates = [\n",
    "                '2016-03-01'\n",
    "                ]\n",
    "\n",
    "end_dates = [\n",
    "            '2016-11-30'\n",
    "            ]\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": os.getenv('api_key'),\n",
    "    \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Create empty dataframe, will be used to append each location's weather data\n",
    "weather_df_3 = pd.DataFrame([])\n",
    "\n",
    "# Loop through all locations and all dates\n",
    "for station in stations:\n",
    "    for start_date, end_date in zip(start_dates, end_dates):\n",
    "        querystring = {\n",
    "                        \"station\": station,\n",
    "                        \"start\": start_date,\n",
    "                        \"end\": end_date,\n",
    "                        \"units\": \"metric\"\n",
    "                        }\n",
    "        \n",
    "        # Request data from url\n",
    "        r = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "        time.sleep(5) #uncomment if you run into a query limit\n",
    "\n",
    "        # Decode response with json decoder\n",
    "        weather_temp_3 = r.json()\n",
    "\n",
    "        # Flatten json response\n",
    "        weather_temp_df_3 = pd.json_normalize(weather_temp_3,\n",
    "                                             sep='_',\n",
    "                                             record_path='data',\n",
    "                                             record_prefix='weather_'\n",
    "                                             )\n",
    "        \n",
    "        # Set the station code for all rows related to the current date range\n",
    "        weather_temp_df_3['station'] = station\n",
    "\n",
    "        # Concatenate dataframes\n",
    "        weather_df_3 = pd.concat([weather_df_3, weather_temp_df_3], ignore_index=True)\n",
    "\n",
    "# Print final dataset weather_df\n",
    "weather_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_3['station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the data for the rest of 2016 of the **other** cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame for the cities to compare\n",
    "\n",
    "\n",
    "# Set the url\n",
    "url = \"https://meteostat.p.rapidapi.com/stations/daily\"\n",
    "\n",
    "# Settings:\n",
    "stations = [\n",
    "#            '74486',  # New York - John F. Kennedy Airport\n",
    "#            '72509',            # Boston Logan International Airport\n",
    "#            '72405',            # Washington D.C. National Airport\n",
    "#            '72502',            # New Jersey - Newark Airport\n",
    "            '72202',            #'Miami International Airport'\n",
    "            '72243',            #'Houston, TX Intercontinental'\n",
    "            '72494',            #'San Francisco Airport'\n",
    "            '72793'             # Seattle-Tacoma Airport\n",
    "            ]\n",
    "\n",
    "start_dates = [\n",
    "                '2016-03-01'\n",
    "                ]\n",
    "\n",
    "end_dates = [\n",
    "            '2016-11-30'\n",
    "            ]\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": os.getenv('api_key'),\n",
    "    \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Create empty dataframe, will be used to append each location's weather data\n",
    "weather_df_4 = pd.DataFrame([])\n",
    "\n",
    "# Loop through all locations and all dates\n",
    "for station in stations:\n",
    "    for start_date, end_date in zip(start_dates, end_dates):\n",
    "        querystring = {\n",
    "                        \"station\": station,\n",
    "                        \"start\": start_date,\n",
    "                        \"end\": end_date,\n",
    "                        \"units\": \"metric\"\n",
    "                        }\n",
    "        \n",
    "        # Request data from url\n",
    "        r = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "        time.sleep(5) #uncomment if you run into a query limit\n",
    "\n",
    "        # Decode response with json decoder\n",
    "        weather_temp_4 = r.json()\n",
    "\n",
    "        # Flatten json response\n",
    "        weather_temp_df_4 = pd.json_normalize(weather_temp_4,\n",
    "                                             sep='_',\n",
    "                                             record_path='data',\n",
    "                                             record_prefix='weather_'\n",
    "                                             )\n",
    "        \n",
    "        # Set the station code for all rows related to the current date range\n",
    "        weather_temp_df_4['station'] = station\n",
    "\n",
    "        # Concatenate dataframes\n",
    "        weather_df_4 = pd.concat([weather_df_4, weather_temp_df_4], ignore_index=True)\n",
    "\n",
    "# Print final dataset weather_df\n",
    "weather_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_4['station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't let the next cell run, because I just copy/pasted the cell from the other notebook, but didn't exactly look over the code**\n",
    "\n",
    "**And I also think we just need to do this part once!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # Add the parent folder to the Python path\n",
    "\n",
    "from sql_functions import get_engine  # Import the function\n",
    "\n",
    "# Now you can use my_function() in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "schema = 'group3'\n",
    "table_name = f'weather_main_cities_rest_of_2016'\n",
    "\n",
    "engine = get_engine()\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        weather_df_3.to_sql(name=table_name, # Name of SQL table variable\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema variable\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "schema = 'group3'\n",
    "table_name = f'weather_other_cities_rest_of_2016'\n",
    "\n",
    "engine = get_engine()\n",
    "\n",
    "if engine!=None:\n",
    "    try:\n",
    "        weather_df_4.to_sql(name=table_name, # Name of SQL table variable\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema variable\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
